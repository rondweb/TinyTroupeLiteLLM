[LLM]
#
# LiteLLM Configuration - Universal LLM Interface
#

# Default provider: openai, anthropic, cohere, replicate, etc.
PROVIDER=vertex_ai

# Default model (will be prefixed with provider if needed)
MODEL=vertex_ai/gemini-2.0-flash

# Universal parameters (LiteLLM handles provider translation)
MAX_TOKENS=4000
TEMPERATURE=1.2
TOP_P=1.0
FREQUENCY_PENALTY=0.0
PRESENCE_PENALTY=0.0
TIMEOUT=60
MAX_ATTEMPTS=5
WAITING_TIME=1
EXPONENTIAL_BACKOFF_FACTOR=5

# Embedding model
EMBEDDING_MODEL=text-embedding-3-small

# Caching settings
CACHE_API_CALLS=False
CACHE_FILE_NAME=litellm_api_cache.pickle

[OpenAI]
#
# OpenAI or Azure OpenAI Service (Legacy - use LLM section above)
#

# Default options: openai, azure
API_TYPE=openai

# Check Azure's documentation for updates here:
# https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-python
AZURE_API_VERSION=2024-08-01-preview

#
# Model parameters
#

MODEL=gpt-4o-mini
LITELLM_MODEL=
MAX_TOKENS=4000
TEMPERATURE=1.2
FREQ_PENALTY=0.0
PRESENCE_PENALTY=0.0
TIMEOUT=60
MAX_ATTEMPTS=5
WAITING_TIME=2
EXPONENTIAL_BACKOFF_FACTOR=5

EMBEDDING_MODEL=text-embedding-3-small 
AZURE_EMBEDDING_MODEL_API_VERSION=2023-05-15

CACHE_API_CALLS=False
CACHE_FILE_NAME=openai_api_cache.pickle

MAX_CONTENT_DISPLAY_LENGTH=1024

[Simulation]
RAI_HARMFUL_CONTENT_PREVENTION=True
RAI_COPYRIGHT_INFRINGEMENT_PREVENTION=True


[Logging]
LOGLEVEL=ERROR
# ERROR
# WARNING
# INFO
# DEBUG
